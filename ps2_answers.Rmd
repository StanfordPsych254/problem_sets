---
title: 'PS#2: Diving into real data using Sklar et al. (2012)'
author: "Mike Frank"
date: "February 9, 2016"
output: 
  html_document:
    toc: true
---

# Intro

This is problem set #2, in which we hope you will practice the visualization package `ggplot2`, as well as hone your knowledge of the packages `tidyr` and `dplyr`. 

Sklar et al. (2012) claims evidence for unconscious arithmetic processing. We're going to do a reanalysis of their Experiment 6, which is the primary piece of evidence for that claim. The data  are generously contributed by Asael Sklar. 

First let's set up a few preliminaries. 

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
library(lme4)

sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95 <- function(x) {sem(x) * 1.96}
```

# Data Prep

First read in two data files and subject info. A and B refer to different trial order counterbalances. 

```{r}
subinfo <- read.csv("http://langcog.stanford.edu/sklar_expt6_subinfo_corrected.csv")
d.a <- read.csv("http://langcog.stanford.edu/sklar_expt6a_corrected.csv")
d.b <- read.csv("http://langcog.stanford.edu/sklar_expt6b_corrected.csv")
```

Gather these datasets into long form and get rid of the Xs in the headers.

```{r}
> ANSWER-START
m.d.a <- d.a %>% 
  gather(subid, rt, starts_with("X")) %>%
  mutate(subid = as.numeric(sub("X","",as.character(subid))))

m.d.b <- d.b %>% 
  gather(subid, rt, starts_with("X")) %>%
  mutate(subid = as.numeric(sub("X","",as.character(subid))))
> ANSWER-END
```

Bind these together. Check out `bind_rows`.

```{r}
> ANSWER-START
m.d <- bind_rows(m.d.a,m.d.b)
> ANSWER-END
```

Merge these with subject info. You will need to look into merge and its relatives, `left_` and `right_join`. Call this dataframe `d`, by convention. 

```{r}
> ANSWER-START
d <- left_join(m.d, subinfo)
> ANSWER-END
```

Clean up the factor structure.

```{r}
d$presentation.time <- factor(d$presentation.time)
levels(d$operand) <- c("addition","subtraction")
```

# Data Analysis Preliminaries

Examine the basic properties of the dataset. First, take a histogram.

```{r}
> ANSWER-START
qplot(rt, data=d)
> ANSWER-END
```

Challenge question: what is the sample rate of the input device they are using to gather RTs?

Sklar et al. did two manipulation checks. Subjective - asking participants whether they saw the primes - and objective - asking them to report the parity of the primes (even or odd) to find out if they could actually read the primes when they tried. Examine both the unconscious and conscious manipulation checks. What do you see? Are they related to one another?

```{r}
> ANSWER-START
qplot(subjective.test, data=subinfo)
qplot(objective.test, data=subinfo)

cor.test(subinfo$objective.test,subinfo$subjective.test) 

ggplot(subinfo, 
       aes(x = subjective.test, y = objective.test)) + 
  geom_jitter(width=.2) + 
  geom_abline(slope=0,intercept=.5,lty=2) + 
  ylim(c(0,1))

> ANSWER-END
```

OK, let's turn back to the measure and implement Sklar et al.'s exclusion criterion. You need to have said you couldn't see (subjective test) and also be not significantly above chance on the objective test (< .6 correct). Call your new data frame `ds`.

```{r}
> ANSWER-START
ds <- d %>% filter(objective.test < .6, 
                   subjective.test==0)
> ANSWER-END
```

# Sklar et al.'s analysis

Sklar et al. show a plot of a "facilitation effect" - the amount faster you are for prime-congruent naming compared with prime-incongruent naming. They then show plot this difference score for the subtraction condition and for the two prime times they tested. Try to reproduce this analysis. 

HINT: first take averages within subjects, then compute your error bars across participants, using the `sem` function (defined above). 

```{r}
> ANSWER-START

ms <- ds %>% 
  group_by(presentation.time, congruent, operand, subid) %>%
  summarise(rt = mean(rt, na.rm=TRUE)) %>%
  group_by(presentation.time, operand, subid, add=FALSE) %>%
  summarise(rt.diff = mean(rt[congruent=="no"] - rt[congruent=="yes"], 
                           na.rm=TRUE)) %>%
  group_by(presentation.time, operand, add=FALSE) %>%
  summarise(sem = sem(rt.diff),
            rt.diff = mean(rt.diff),
            n = n())

> ANSWER-END
```

Now plot this summary, giving more or less the bar plot that Sklar et al. gave (though I would keep operation as a variable here. Make sure you get some error bars on there (e.g. `geom_errorbar` or `geom_linerange`). 

```{r}
> ANSWER-START

ggplot(ms, aes(x = presentation.time, y = rt.diff, fill = operand)) + 
  facet_grid(. ~ operand) + 
  geom_bar(stat = "identity") + 
  geom_errorbar(aes(ymin=rt.diff - sem, ymax=rt.diff + sem), 
             position = position_dodge(width=1), width=.1) + 
  ylab("Reaction Time Difference (ms)") + 
  xlab("Presentation Time Condition (ms)")

> ANSWER-END
```

What do you see here? How close is it to what Sklar et al. report? Do the error bars match? How do you interpret these data? 

Challenge problem: verify Sklar et al.'s claim about the relationship between RT and the objective manipulation check.

```{r}
> ANSWER-START

mss <- d %>% 
  group_by(presentation.time, congruent, operand, objective.test, subid) %>%
  summarise(rt = mean(rt, na.rm=TRUE)) %>%
  group_by(presentation.time, operand, subid, objective.test, add=FALSE) %>%
  summarise(rt.diff = mean(rt[congruent=="no"] - rt[congruent=="yes"], 
                           na.rm=TRUE)) 

qplot(objective.test,rt.diff,facets = . ~ operand,
      colour=presentation.time,
      data=mss) + 
  geom_abline(slope=0,intercept=.5,lty=2) + 
  geom_smooth(se=FALSE,method="lm") + 
  xlab("Objective Test Score") + 
  ylab("Reaction Time Difference (ms)")
  
> ANSWER-END
```

# Your own analysis

Show us what you would do with these data, operating from first principles. What's the fairest plot showing a test of Sklar et al.'s original hypothesis?

```{r}
> ANSWER-START

ms <- d %>% 
  group_by(presentation.time, congruent, operand, subid) %>%
  summarise(rt = mean(rt, na.rm=TRUE)) %>%
  group_by(presentation.time, congruent, operand, add=FALSE) %>%
  summarise(sem = ci95(rt), 
            rt = mean(rt))

ggplot(ms, aes(x= presentation.time, y = rt, colour=congruent)) + 
  geom_line(aes(group=congruent)) + 
  geom_pointrange(aes(ymin=rt-sem,ymax=rt+sem), 
                  position=position_dodge(width=.1)) + 
  facet_grid(.~operand) + 
  xlab("Presentation Time (ms)") + 
  ylab("Reaction Time Difference (ms)")
  
> ANSWER-END
```

Challenge problem: Do you find any statistical support for Sklar et al.'s findings?

```{r}
> ANSWER-START

mod <- lmer(rt ~ presentation.time * congruent * operand +
       (congruent * operand | subid) + (congruent | prime),
     data=ds)
summary(mod)

> ANSWER-END
```

